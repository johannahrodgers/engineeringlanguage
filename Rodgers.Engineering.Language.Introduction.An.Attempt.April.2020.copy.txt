Engineering Language: Teaching Machines to Read and Write in the “Long” 20th c. 
An Attempt at an Introduction
Johannah Rodgers
April 13, 2020

Although we don’t often say it in such terms today, a human is a computer.  The next question, at least from a logical perspective, then might be: does that mean a computer is a human?  The answer to the second question is, obviously, no.  Humans are biological organisms.  Computers, at least as we define them today, are non-biological technological objects.  A computer is a human creation.  It is a tool and an invention.  It is not a living thing.  Nevertheless, let’s consider the many ways in which humans function as much like computers, objects that I like to refer to these days as “sophisticated” [understatement!] calculators, as they do as biological organisms.  Both humans and computers can be represented and defined as symbol making machines.  Further, inscribed verbal language, or models and descriptions of such systems, are deployed by both.   

Since at least the 17th century and probably earlier there have been attempts to represent and understand reality in purely rational terms from the perspective of mind of man, itself perceived to be infinite, using the tools designed by man to enable and facilitate this process. For reasons related to what we now call socio-cultural, economic, and political interests, the all too glaring circularity of such reasoning, i.e., that with man made tools a potentially infinite man-made world is possible were not questioned.  And, as long as there were sufficient natural resources to support a non-self-sustaining technological system there was not a mandate to do so. Questions were raised, but a whole range of assumptions underlying the progress of technologies were not themselves subject to debate. There was always more. There was always an elsewhere to explore and exploit. Today, that elsewhere is most often non-earth based since the resources of this planet have been if not yet depleted, certainly documented and prepared for depletion. It is time to subject this model to questions that have for too long seemed postponable, exportable, simply difficult, uncomfortable or potentially disruptive to the lives that many in the west have come to take for granted.

This book is a plea for humans to consider what it means to human in a world without infinite resources. Further it is a plea for humans to consider digital computing machines and devices as human built tools with great capabilities and not as potentially magical solutions.  Humans use their language to expand the capabilities of machines processing and use machine languages derived from human language to accelerate the advancement of select attributes and capabilities of humans in the interest of the survival of the species based on only a limited understanding of the species and based on the assumption that dominance of every other species defines survival. How do we define intelligence?

Digital computers and their applications have many functions in the 21st-century and can be defined and discussed in many different ways.  Like all technologies they “create” change in the society in which they are adopted. However I want to consider digital computers and their applications from a more limited perspective as reading and writing machines. This perspective will for some encompass the basic operations of digital computers and for others will be seen to cover only a small part. That is fine with me. I am aware that tin many ways computers have been and will always be very much “like an elephant,” too large and diverse to clearly represent in their totality. I don't want to find agreement regarding the ultimate answer of what computers are. However I do want to find some consensus regarding how we talk about certain attributes of these machines  which are regularly represented as having a superhuman And practically godlike powers.

First and foremost they are superhuman. They were designed and built to be that way. From the viewpoint of what computers can do, they are remarkable and will outpace any human at calculation. But just as I can expect that my cat will beat me in a race up the stairs, I also know that a computer can complete certain tasks faster than I ever could. The question the remains; why do we continue to be surprised by such acts and to celebrate them as if they are events worthy of celebration or, on our bads days, of our pending demise? Haven't we already sufficiently celebrated the remarkableness of this speed and capacity? At what point do we stop being amazed? Perhaps never. Perhaps the cycles of amazement are just part of what it is to be human. Nevertheless, I hope that some of what I will talk about today may make you pause before attributing Godlike or magical attributes to digital computing systems and devices and their applications. For they are after all human made. While this is the basic structure of a digital computer this model shows only the hardware [input/output/cpu/short term memory/long term memory]. The software is what instructs the system and its operation and believe it or not those instructions are given in a manner that is in many ways identical to instructions given to a human who is seeking to operate something or to learn something. The instructions are related and then stored and then enacted. However, as much as schematic overviews of the processing structures of humans and computers may resemble one another [compare psychological model of the writing subject with overview of a computing system], they differ with respect to two key issues: 1/ memory and 2/ language. Computers do not forget and they also do not speak natural languages; they don't actually “speak” at all however they do respond to instructions. They turn on and they turn off. When they are on we can ask them to do things and they can tell us how they are progressing with those tasks. So much money time and brain power and resources and labor have been dedicated to these machines that they can do quite a number of things, They can turn other devices on and off, they can even remember things for us and remind us every microsecond that these things need to be done. We have taught computers the rules of chess, the rules of flight scheduling, the rules of tax filing, and rules of blank. We are now in the process of “teaching” computers how to “learn,” but these terms, like the terms “reading” and “writing” when used in relation to the operations and functions of computing machines must remain in quotation marks.  It is we who have taught computers these things. And it is on the conceptions and  methods and processes of these very limited definitions of “teaching” and” learning”  that I want to draw your attention to. We have taught computers many skills all of which are based on the computer's ability to read and write instructions.

Although we are told over and over again how important reading and writing are in the operations of digital computing machines and networks, these two terms reading and writing remain highly ambiguous, at least in some disciplines.  From the engineering perspective and in the context of the history of information and communications technological development, a technical definition has been assigned to each.  Writing is the inscription of a message in a particular code in some type of transmissible media. It is an encoding.  Reading is the successful reception of this message; it is a decoding of the encoded message. As far as machines go this is a satisfactory definition. Further, to the extent that humans behave as coding and decoding machines, this is also a satisfactory definition. However humans are not machines. They can be represented as such in their operations and metaphorically portrayed as mechanical systems. But such descriptions and conceptions will always only represent the part of the “workings” of a human. As biological and social animals humans have ways of reacting to and understanding the world that are not encompassed by the operations of even a highly intelligent machine.  Some may say that this fact will no longer be true in a certain span of time.  In response to such claims, I ask that you consider the fact that there do not yet exist any human made tools that function in a strictly ecological manner.  Even something as apparently simple as the making of water cannot be done without the destruction and net loss of natural resources.

How did the computer learn to read? How did the computer learn to write? Well these are complex questions with complex answers. But I think it is worth thinking through both questions and answers neither is singular or simple. How could they be? 1/  humans are more complex than digital computers; 2/ humans are in the process of making digital computers more complex; 3/ analogies that have been made between the operations of computers and humans may be self-fulfilling prophecies or feedback loops.  The complex operations of such metaphoricity need themselves to be considered, discussed, and funded at the same levels as defense-funded hardware and software initiatives; 4/ a simulation of a human is not a human even if it may appear to be.

Despite the explicitly stated importance of communication to the fields of cybernetics and information processing (Wiener), the field of writing studies continues to play catch up in its ability to adequately theorize and describe the roles and functions inscribed verbal language as it is used by both humans and machines.  As the linguist Roy Harris pointed out in his book “Rethinking Writing,” although, in the field of mathematics, there has long been a distinction made between a notation, i.e., a figure, and a script, “there is no such simple and perspicuous statement available in the cases of language” (94).  This inadequacy results, in part, from the very breadth of the field (doubtful) as well as its intertwinement with the reality we live in , i.e., we can only talk about reality using language.  However, the need to articulate exactly what is going on with literacy practices and how today’s multimodal and highly automated acts of communication relate to the current practices and histories of college writing instruction make it important to flesh out what has not been fleshed out in writing studies.  Systems of shorthand, which are one of the oldest technologies of inscription for recording, reproducing, and storing verbal language offer a repository for better understanding the instrumental elements of verbal language and its adaptations in digital environments. Verbal=spoken, alphabetic, instrumental

The alphabet is a notational system for recording verbal concepts.  

Notation=eastern v. western arabic numerals
Writing system=arabic decimal v. octal

cognitive/social technologies

By the mid-19th c., the alphabet was becoming refined as a tool for social control.  At the same time, the alphabet as one part of the social and material technologies of literacy was being re-engineered.  Alphabetic writing as one of an increasing number of information and communications technologies available was being critiqued in ways it never had been previously.  Why?  For what purposes?  For what reasons?  

Combining a post-colonial perspective on the functions of writing and national literatures with a historiography of composition and linguistics in the U.S., Rodgers shows that as the key functions of inscribed verbal communication were being transferred to machines, language education both shapes and informs this transfer of knowledge.  In the process its former purposes are fossilized,  thus radically changing their significance and value..  

From the most abstract perspective, verbal language is a code.   

Travel, conquest, entertainment, business.  Enclosure.  The remaking of the natural as artificial.  You are a machine.  

Writing and mechanization.  


Communicating@the speed of light.  It Is “nothing more” than electricity that allows us to enter a different frame of reference.  Physics you could say, though that is a vast subject.  What I'm talking about when I say physics is the experience of the world as elemental entities.  Let's dispose of biological limitation and enter a world of particles parentheses particulate matter close parentheses; let's change the frame of reference for time and space; let's use our disembodied sense representation to participate in a nonhuman experience of the universe: you can be an ant or an ounce or a squirrel or a chicken or a virus, or at least see the world from the perspective of these agents assuming vision is the calculation of reference points.  All you need to do is change the spatial perspective and the data input. [The processing of this sense data remains a sticking point since we still know so little about how human and nonhuman brains work.  For now, we can only use the little we know about the operations of the brain as a model for synthesizing experiential data.  This will soon change.] The question though is whether, even understanding the world from the perspective of a virus. we will ever really be able to escape our own frame of reference and understanding. As an equation or proposition,  that seems simple.  In reality, our imaginations, no matter how vast, are always informed by our own point of view. As a result when we consider the language of aliens or how acts of communication are defined, we have only our understanding of how language and communication and understanding operate and function. Should we dedicate more time and resources to understanding how these things operate and function for humans, or should we move on to attempts to objectively model these processes from a nonhuman perspective? We assume that numbers are nonhuman but that in itself is a big assumption given the fact that numbers were invented by humans.  How do you come to terms with the fact that there is no objectivity, vis a vis, seeing or understanding things from a nonhuman perspective? Every perspective or frame of reference available to humans is modeled on human models.  Objectivity is nothing more than an act of translation from one representational sign system to another.  Some sign systems appear to be more objective because of their characteristics but they are not actually objective. They merely appear to be objective in a comparative context with other representational sign systems.  If I “walk” through the world like a virus will I understand its desires? Do virii have desires given the fact that this category of experience may be a uniquely human one?  We like to blame verbal language for ambiguity but there are other issues at play, mostly our inability to ever stop being human.  We have yet to figure out a way to remove a human consciousness from an experiential context and the information used to make sense of that context



When Wiener talks about messages and communications facilities he is for the most part talking about Communication in printed English. What processes are involved in defining natural language as a computational problem? When does this occur? How does this occur? What is the sector? In his 1928 article heart rate formulates the quantity of information as a constant computation problem when he conceives of the equation H equals N log ass

The index was originally the name of one part of an instrument for reading the stars.

You begin to think about all of those grade school and high school visits to planetariums differently once you understand that it is literally from reading the stars that many aspects and functions of the printed book are derived


